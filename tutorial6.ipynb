{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consumer Demand\n",
    "Consider a consumer with an income of $I$, who is choosing between $n$ different goods.\n",
    "We encode the prices of these goods as a vector $p \\in \\mathbb R^n$.\n",
    "We assume that they have Cobb-Douglass preferences:\n",
    "\n",
    "$$ u(x) = \\sum_{i=1}^n \\alpha_i \\log(x_i) $$\n",
    "where $\\alpha$ is a vector of parameters satisfying $\\sum \\alpha_i = 1$.\n",
    "This looks like a constrained optimization problem:\n",
    "\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "    \\max_{x \\in \\R^n}\\;\\;   &  \\sum_{i=1}^n \\alpha_i \\log(x_i) \\\\ \n",
    "    \\text{s.t. } \\;\\;       &  p \\cdot x \\leq I \\\\ \n",
    "                            &  x_i \\geq 0\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    "\n",
    "This problem is nice because it has known solutions in closed form, so we can always go back and check our work!\n",
    "If we take the Lagrangian for this problem, we get:\n",
    "$$ \\mathcal L = \\sum_{i=1}^n \\alpha_i \\log(x_i) - \\lambda (p \\cdot x - I) $$\n",
    "and a set of first order conditions \n",
    "\\begin{align*}\n",
    "    0 = {\\partial \\mathcal L \\over \\partial x_i}     &= {\\alpha_i \\over x_i} - \\lambda p_i \\\\\n",
    "    0 = {\\partial \\mathcal L \\over \\partial \\lambda} &= p \\cdot x - I \n",
    "\\end{align*}\n",
    "\n",
    "We can show that these imply:\n",
    "$$ p_i x_i = {\\alpha_i \\over \\lambda} \n",
    "\\Rightarrow I = \\sum_{i=1}^n p_i x_i \n",
    "= {1 \\over \\lambda} \\sum_{i=1}^n \\alpha_i \n",
    "= {1 \\over \\lambda} $$\n",
    "So we obtain that \n",
    "$$ x_i = {\\alpha_i \\over p_i} I $$\n",
    "The consumers spend a constant share of their income $\\alpha_i$ on good $i$.\n",
    "This should all look very familiar.\n",
    "\n",
    "## The Plan\n",
    "We are going to solve this problem in three different ways:\n",
    "1. Sequential Quadratic Programming\n",
    "2. Penalty Function\n",
    "3. Augmented Lagrangian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant p. This may fail, cause incorrect answers, or produce other errors.\n",
      "WARNING: redefinition of constant α. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       " 0.07714052044211762\n",
       " 0.1588154045133561\n",
       " 0.09263306228889596\n",
       " 0.168645734917304\n",
       " 0.1090474396670803\n",
       " 0.10093276583564408\n",
       " 0.11288085589914773\n",
       " 0.05766901929390376\n",
       " 0.05798324647439323\n",
       " 0.0642519506681571"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Optim\n",
    "using ForwardDiff: gradient, hessian, jacobian\n",
    "using Random\n",
    "using LinearAlgebra\n",
    "using TransformVariables\n",
    "\n",
    "# Set the seed so this is reproducible\n",
    "Random.seed!(1257)\n",
    "\n",
    "# Setup our utility function\n",
    "u(x, α) = sum(α[i] * log(x[i]) for i in eachindex(x, α))\n",
    "\n",
    "# Make some test parameters\n",
    "const p = rand(10); p[1] = 1          # random prices -- normalize \n",
    "const α = rand(10); α .*= 1/sum(α)     # ensure that α sum to 1\n",
    "\n",
    "# We'll assume that income is 1 (to make things easy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Quadratic Programming\n",
    "Remember that SQP is just Newton's method on the Lagrangian. \n",
    "Let's recall our update rule for Newton's method:\n",
    "if $f: \\mathbb R^n \\to \\mathbb R$, and we want to maximize $f$, we start with $x_0$ and update according to \n",
    "$$ D^2f(x_k) (x_{k+1} - x_{k}) = -Df(x_k) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newton (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function newton(f, x0; tol = 1e-8, itermax = 100, trace=false)\n",
    "    x    = copy(x0)\n",
    "    err  = Inf\n",
    "    iter = 0\n",
    "    while ! (err < tol) && iter < itermax\n",
    "\n",
    "        # Calculate the gradient and the Hessian\n",
    "        fx  = f(x)\n",
    "        Df   = gradient(f, x)\n",
    "        D²f  = hessian(f, x)\n",
    "\n",
    "        # search direction\n",
    "        sk = -D²f\\Df\n",
    "\n",
    "        # update x\n",
    "        x′ = x + sk\n",
    "\n",
    "        # Check for convergence\n",
    "        err = norm(x′ - x)/max(norm(x),1)\n",
    "\n",
    "        # copy x′ to be old x and start again\n",
    "        x .= x′\n",
    "        iter += 1\n",
    "\n",
    "        trace && @info \"Trace Information\" iter x fx = f(x)\n",
    "    end\n",
    "\n",
    "    return (;fx = f(x), x, iter)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(fx = -0.7531257099977997, x = [-2.5621265795030403, -1.1814427295803822, -0.2961920258578519, -0.23259450675866966, 2.4482446887778244, -1.1298074277450192, -0.1524034471189933, -2.628294560937256, -2.7192404969250115, -1.987217713423624, -1.7762675146586297e-16], iter = 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting up the Lagrangian\n",
    "L(x, λ, α, p) = u(x, α) - λ * (dot(x, p) - 1)\n",
    "\n",
    "# Let's solve the problem:\n",
    "function h(z)\n",
    "    # we need a domain transformation to ensure we're only searching over positive numbers for x\n",
    "    t = as(Array, as_positive_real, 11)\n",
    "    y = transform(t, z)\n",
    "\n",
    "    # separate x and λ and call the Lagrangian\n",
    "    L(y[1:end-1], y[end], α, p)\n",
    "end\n",
    "ret = newton(h, ones(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×2 Matrix{Float64}:\n",
       "  0.0771405   0.0771405\n",
       "  0.306836    0.306836\n",
       "  0.743645    0.743645\n",
       "  0.792475    0.792475\n",
       " 11.568      11.568\n",
       "  0.323095    0.323095\n",
       "  0.858642    0.858642\n",
       "  0.0722015   0.0722015\n",
       "  0.0659248   0.0659248\n",
       "  0.137076    0.137076"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## We still need to get our solution back out:\n",
    "\n",
    "# Apply the domain transformation again to get \n",
    "ys = transform(as(Array, as_positive_real, 11), ret.x)\n",
    "xs = ys[1:end-1]\n",
    "\n",
    "# Compare to the true solution\n",
    "@assert xs ≈ α./p\n",
    "hcat(xs, α./p)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalty Method\n",
    "Now, we're going to try an approach with a penalty function.  We will keep using our Newton's method implementation on the inside.\n",
    "\n",
    "Recall that the penalty method approach solves a sequence of problems:\n",
    "\\begin{equation}\n",
    "    \\max_{x \\in \\mathbb R^n} f(x) - P_k \\sum_{i=1}^m g_i(x)^2\n",
    "\\end{equation}\n",
    "\n",
    "We need a function that takes in the objective, our constraints, and a penalty value $P_k$.  It should return the solved value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solve_penalty (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function solve_penalty(P, x0)\n",
    "    # Still need the domain transform\n",
    "    t = as(Array, as_positive_real, length(x0))\n",
    "    \n",
    "    # Set up the penalized objective \n",
    "    function objective(y)\n",
    "        x  = transform(t, y) \n",
    "        \n",
    "        return u(x, α) - P * (dot(p, x) - 1)^2\n",
    "    end\n",
    "\n",
    "    # Solve with Newton's method\n",
    "    y0  = inverse(t, x0)\n",
    "    ret = newton(objective, y0)\n",
    "\n",
    "    # Keep things interpretable\n",
    "    ret = (; ret..., x = transform(t, ret.x))\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's observe that if you start with a very large value of $P$, the poor conditioning of the problem shows up.  We get completely incorrect answers!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×2 Matrix{Float64}:\n",
       " 0.225656   0.0771405\n",
       " 0.225194   0.306836\n",
       " 0.231865   0.743645\n",
       " 0.221432   0.792475\n",
       " 0.213316  11.568\n",
       " 0.223461   0.323095\n",
       " 0.221471   0.858642\n",
       " 0.223109   0.0722015\n",
       " 0.224523   0.0659248\n",
       " 0.224367   0.137076"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ret = solve_penalty(1e20, ones(10))\n",
    "hcat(ret.x, α./p)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we happen to start with a $P$ that's large, but not _too_ large, it still doesn't save us.  \n",
    "We get the right answer, but look at how many iterations it takes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: We took a lot of iterations to get here\n",
      "│   iter = 72\n",
      "└ @ Main /Users/jacobadenbaum/Dropbox/Teaching/2023/Programming for Economics/Lectures/Optimization/tutorial6.ipynb:2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10×2 Matrix{Float64}:\n",
       "  0.0771405   0.0771405\n",
       "  0.306836    0.306836\n",
       "  0.743645    0.743645\n",
       "  0.792475    0.792475\n",
       " 11.568      11.568\n",
       "  0.323095    0.323095\n",
       "  0.858642    0.858642\n",
       "  0.0722015   0.0722015\n",
       "  0.0659248   0.0659248\n",
       "  0.137076    0.137076"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ret = solve_penalty(1e12, ones(10))\n",
    "@info \"We took a lot of iterations to get here\" iter = ret.iter\n",
    "\n",
    "# Compare to the truth\n",
    "hcat(ret.x, α./p)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try instead to solve the problem with a sequence of penalty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Trace\n",
      "│   iter = 1\n",
      "│   P = 10\n",
      "│   penalty_violation = 0.3660254037844386\n",
      "└ @ Main /Users/jacobadenbaum/Dropbox/Teaching/2023/Programming for Economics/Lectures/Optimization/tutorial6.ipynb:27\n",
      "┌ Info: Trace\n",
      "│   iter = 2\n",
      "│   P = 100\n",
      "│   penalty_violation = 0.047722557505166296\n",
      "└ @ Main /Users/jacobadenbaum/Dropbox/Teaching/2023/Programming for Economics/Lectures/Optimization/tutorial6.ipynb:27\n",
      "┌ Info: Trace\n",
      "│   iter = 3\n",
      "│   P = 1000\n",
      "│   penalty_violation = 0.004975246918103915\n",
      "└ @ Main /Users/jacobadenbaum/Dropbox/Teaching/2023/Programming for Economics/Lectures/Optimization/tutorial6.ipynb:27\n",
      "┌ Info: Trace\n",
      "│   iter = 4\n",
      "│   P = 10000\n",
      "│   penalty_violation = 0.000499750249687958\n",
      "└ @ Main /Users/jacobadenbaum/Dropbox/Teaching/2023/Programming for Economics/Lectures/Optimization/tutorial6.ipynb:27\n",
      "┌ Info: Trace\n",
      "│   iter = 5\n",
      "│   P = 100000\n",
      "│   penalty_violation = 4.99975002494768e-5\n",
      "└ @ Main /Users/jacobadenbaum/Dropbox/Teaching/2023/Programming for Economics/Lectures/Optimization/tutorial6.ipynb:27\n",
      "┌ Info: Trace\n",
      "│   iter = 6\n",
      "│   P = 1000000\n",
      "│   penalty_violation = 4.999975000252732e-6\n",
      "└ @ Main /Users/jacobadenbaum/Dropbox/Teaching/2023/Programming for Economics/Lectures/Optimization/tutorial6.ipynb:27\n",
      "┌ Info: Trace\n",
      "│   iter = 7\n",
      "│   P = 10000000\n",
      "│   penalty_violation = 4.999997500476638e-7\n",
      "└ @ Main /Users/jacobadenbaum/Dropbox/Teaching/2023/Programming for Economics/Lectures/Optimization/tutorial6.ipynb:27\n",
      "┌ Info: Trace\n",
      "│   iter = 8\n",
      "│   P = 100000000\n",
      "│   penalty_violation = 4.99999974756804e-8\n",
      "└ @ Main /Users/jacobadenbaum/Dropbox/Teaching/2023/Programming for Economics/Lectures/Optimization/tutorial6.ipynb:27\n",
      "┌ Info: Trace\n",
      "│   iter = 9\n",
      "│   P = 1000000000\n",
      "│   penalty_violation = 4.999999969612645e-9\n",
      "└ @ Main /Users/jacobadenbaum/Dropbox/Teaching/2023/Programming for Economics/Lectures/Optimization/tutorial6.ipynb:27\n",
      "┌ Info: Trace\n",
      "│   iter = 10\n",
      "│   P = 10000000000\n",
      "│   penalty_violation = 4.999998193255806e-10\n",
      "└ @ Main /Users/jacobadenbaum/Dropbox/Teaching/2023/Programming for Economics/Lectures/Optimization/tutorial6.ipynb:27\n",
      "┌ Info: Trace\n",
      "│   iter = 11\n",
      "│   P = 100000000000\n",
      "│   penalty_violation = 5.000000413701855e-11\n",
      "└ @ Main /Users/jacobadenbaum/Dropbox/Teaching/2023/Programming for Economics/Lectures/Optimization/tutorial6.ipynb:27\n",
      "┌ Info: Trace\n",
      "│   iter = 12\n",
      "│   P = 1000000000000\n",
      "│   penalty_violation = 5.000000413701855e-12\n",
      "└ @ Main /Users/jacobadenbaum/Dropbox/Teaching/2023/Programming for Economics/Lectures/Optimization/tutorial6.ipynb:27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(fx = -0.7531257099972999, x = [0.07714052044215622, 0.3068357381174742, 0.7436446153139314, 0.7924748515785076, 11.56802340627432, 0.3230954696551163, 0.8586417942936179, 0.07220149254441155, 0.06592480550955669, 0.137076280871644], iter = 12, num_evals = 37)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function penalty_method(x0; tol = 1e-12, γ = 10, trace = false)\n",
    "\n",
    "    iter = 0\n",
    "    num_evals = 0\n",
    "    P = 1\n",
    "    x = copy(x0)\n",
    "    while true\n",
    "        # Solve with penalty parameter p\n",
    "        ret = solve_penalty(P, x)\n",
    "\n",
    "        # Keep track of the total number of function evals (really, Newton steps in this case)\n",
    "        num_evals += ret.iter\n",
    "\n",
    "        # Check whether the constraints are violated\n",
    "        x  = ret.x\n",
    "        gx = (dot(p, x) - 1)\n",
    "\n",
    "        # If gx is small enough, we're done\n",
    "        gx < tol && break\n",
    "\n",
    "        # Otherwise we keep going, using the solution as a warmstart\n",
    "        # Increment P up\n",
    "        x .= ret.x\n",
    "        P *= γ\n",
    "        iter += 1\n",
    "\n",
    "        trace && @info \"Trace\" iter P penalty_violation = gx\n",
    "    end\n",
    "\n",
    "    return (; fx = u(x, α), x, iter, num_evals)\n",
    "end\n",
    "\n",
    "penalty_ret = penalty_method(ones(10), trace=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we got the right answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×2 Matrix{Float64}:\n",
       "  0.0771405   0.0771405\n",
       "  0.306836    0.306836\n",
       "  0.743645    0.743645\n",
       "  0.792475    0.792475\n",
       " 11.568      11.568\n",
       "  0.323095    0.323095\n",
       "  0.858642    0.858642\n",
       "  0.0722015   0.0722015\n",
       "  0.0659248   0.0659248\n",
       "  0.137076    0.137076"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hcat(penalty_ret.x, α./p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented Lagrangian Approach\n",
    "Let's finally try to implement this using the augmented lagrangian method.\n",
    "Recall that now we solve a sequence of problems:\n",
    "\\begin{equation}\n",
    "    \\max_{x \\in \\mathbb \\R^n} f(x) - {P_k \\over 2} \\sum_{i=1}^m g_i(x)^2 - \\sum_{i=1}^m \\lambda_i^k g_i(x)\n",
    "\\end{equation}\n",
    "and where we update $\\lambda$ according to \n",
    "$$ \\lambda_i^{k+1} = \\lambda_i^k + P_k g_i(x_k) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "augmented_lagrangian (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, we need to solve the inner augmented lagrangian problem\n",
    "# we'll use newton's method again\n",
    "function augmented_lagrangian_inner(f, g, P, λ, x0)\n",
    "\n",
    "    function objective(x)\n",
    "        gx = g(x)\n",
    "        f(x) - 1/2 * P * dot(gx, gx) - dot(λ, gx)\n",
    "    end\n",
    "\n",
    "    # Solve the augmented problem\n",
    "    ret = newton(objective, x0)\n",
    "\n",
    "    return ret\n",
    "end\n",
    "\n",
    "function augmented_lagrangian(f, g, x0; tol = 1e-8, γ = 10, trace=false)\n",
    "\n",
    "    # setup \n",
    "    gx = g(x0)\n",
    "    λ  = zeros(size(gx))\n",
    "    P  = 1.0\n",
    "    x  = copy(x0)\n",
    "    num_evals = 0\n",
    "    iter = 0\n",
    "\n",
    "    while true \n",
    "        \n",
    "        # Solve the inner problem \n",
    "        ret = augmented_lagrangian_inner(f, g, P, λ, x)\n",
    "        x′  = ret.x \n",
    "        num_evals += ret.iter\n",
    "        iter += 1\n",
    "        # Update λ\n",
    "        gx  = g(x′)\n",
    "        λ′  = gx .* P\n",
    "\n",
    "        # Check if we're violating the constraints\n",
    "        err = dot(g(x), g(x))\n",
    "        if err < tol\n",
    "            break\n",
    "        else # otherwise keep going\n",
    "            P *= γ\n",
    "            x .= x′\n",
    "            λ .= λ′\n",
    "            trace && @info \"Trace\" iter P err penalty_violation = gx\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return (; fx = f(x), x, λ, num_evals, iter)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret = (fx = -0.7530611550166022, x = [-2.5620620245218433, -1.1813781745991847, -0.29612747087665425, -0.23252995177747215, 2.4483092437590224, -1.1297428727638217, -0.15233889213779583, -2.6282300059560586, -2.7191759419438135, -1.9871531584424265], λ = fill(0.6455706491514945), num_evals = 29, iter = 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Trace\n",
      "│   iter = 1\n",
      "│   P = 10.0\n",
      "│   err = 123.44545286449578\n",
      "│   penalty_violation = 0.6180339887498947\n",
      "└ @ Main /Users/jacobadenbaum/Dropbox/Teaching/2023/Programming for Economics/Lectures/Optimization/tutorial6.ipynb:45\n",
      "┌ Info: Trace\n",
      "│   iter = 2\n",
      "│   P = 100.0\n",
      "│   err = 0.38196601125010493\n",
      "│   penalty_violation = 0.03483075993763296\n",
      "└ @ Main /Users/jacobadenbaum/Dropbox/Teaching/2023/Programming for Economics/Lectures/Optimization/tutorial6.ipynb:45\n",
      "┌ Info: Trace\n",
      "│   iter = 3\n",
      "│   P = 1000.0\n",
      "│   err = 0.0012131818378330172\n",
      "│   penalty_violation = 0.006452809627836453\n",
      "└ @ Main /Users/jacobadenbaum/Dropbox/Teaching/2023/Programming for Economics/Lectures/Optimization/tutorial6.ipynb:45\n",
      "┌ Info: Trace\n",
      "│   iter = 4\n",
      "│   P = 10000.0\n",
      "│   err = 4.163875209309883e-5\n",
      "│   penalty_violation = 0.00035436479794848097\n",
      "└ @ Main /Users/jacobadenbaum/Dropbox/Teaching/2023/Programming for Economics/Lectures/Optimization/tutorial6.ipynb:45\n",
      "┌ Info: Trace\n",
      "│   iter = 5\n",
      "│   P = 100000.0\n",
      "│   err = 1.2557441002506774e-7\n",
      "│   penalty_violation = 6.455706491514945e-5\n",
      "└ @ Main /Users/jacobadenbaum/Dropbox/Teaching/2023/Programming for Economics/Lectures/Optimization/tutorial6.ipynb:45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(fx = -0.7530611550166022, x = [-2.5620620245218433, -1.1813781745991847, -0.29612747087665425, -0.23252995177747215, 2.4483092437590224, -1.1297428727638217, -0.15233889213779583, -2.6282300059560586, -2.7191759419438135, -1.9871531584424265], λ = fill(0.6455706491514945), num_evals = 29, iter = 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's apply now \n",
    "function obj(y) \n",
    "    t = as(Array, as_positive_real, 10)\n",
    "    x = transform(t, y)\n",
    "    return u(x, α)\n",
    "end\n",
    "\n",
    "function constraints(y)\n",
    "    t = as(Array, as_positive_real, 10)\n",
    "    x = transform(t, y)\n",
    "    return dot(x, p) - 1\n",
    "end\n",
    "\n",
    "ret = augmented_lagrangian(obj, constraints, ones(10), trace=true)\n",
    "@show ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×2 Matrix{Float64}:\n",
       "  0.0771455   0.0771405\n",
       "  0.306856    0.306836\n",
       "  0.743693    0.743645\n",
       "  0.792526    0.792475\n",
       " 11.5688     11.568\n",
       "  0.323116    0.323095\n",
       "  0.858697    0.858642\n",
       "  0.0722062   0.0722015\n",
       "  0.0659291   0.0659248\n",
       "  0.137085    0.137076"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare values\n",
    "t = as(Array, as_positive_real, 10)\n",
    "x = transform(t, ret.x)\n",
    "\n",
    "hcat(x, α./p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0-beta4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0-beta4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
